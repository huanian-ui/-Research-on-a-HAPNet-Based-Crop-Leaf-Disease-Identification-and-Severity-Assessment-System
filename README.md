# -Research-on-a-HAPNet-Based-Crop-Leaf-Disease-Identification-and-Severity-Assessment-System
Against the backdrop of rapid development in Smart Agriculture 4.0, early identification, severity assessment, and precise diagnosis of crop diseases have become critical technological demands for enhancing agricultural efficiency and reducing pesticide usage.
Regarding Question 1: This study constructed a hierarchical classification model based on an improved Swin-Tiny architecture for 61 fine-grained "crop–disease–severity" categories. By integrating data cleaning, domain randomization augmentation, label embedding, and a joint loss function, the model effectively enhanced recognition capabilities for long-tail categories and complex backgrounds. Results demonstrate: The model achieves Top-1 Accuracy = 85%, Top-5 Accuracy = 93%, Macro-F1 = 0.77, and Weighted-F1 = 0.85, with learned features maintaining high accuracy (0.7–1.0) across most categories. This establishes a unified, high-quality visual representation foundation for subsequent few-shot learning, severity assessment, and multi-task collaboration, forming the core backbone of the entire diagnostic system.
 Regarding Question 2: Under the constraint of only 10 samples per class, this study proposes the HAPNet model. It significantly mitigates overfitting through "species–disease– fine-grained" hierarchical prototype learning, lesion saliency enhancement, and EMA self-supervised consistency constraints. This enables the model to achieve a high-level performance of Weighted F1 = 0.7384 even under 10-shot conditions. Results demonstrate that HAPNet maintains strong diagnostic capability under extremely high annotation costs and small-sample environments. Its excellent interpretability further validates the model's practical value for fine-grained disease identification tasks.
 Regarding Question 3: This study constructs the HAPNet-SG model by introducing ordered regression and disease auxiliary supervision, enabling severity learning to follow a continuous structure of "healthy → mild → moderate → severe." Conclusions indicate: On the official validation set, the four severity levels achieved F1 scores of 0.97 (S0), 0.98 (S1), 0.99 (S2), and 0.995 (S3), with an overall Macro-F1 of 0.9847. The confusion matrix reveals minimal errors between adjacent severity levels, with virtually no misclassifications spanning more than two levels. The error distance histogram shows nearly 100% of |predicted−actual| = 0. Grad-CAM visualizations highlight highly interpretable lesion-focused regions.
 Regarding Question 4: This study constructs HAPNet-MTL with a shared backbone to achieve joint learning for disease classification and severity prediction. By leveraging semantic complementarity and feature sharing, it enhances performance across both tasks. Conclusions indicate: Experiments demonstrate that the two tasks mutually reinforce rather than compete: Disease classification: Macro-F1 improved from 0.7384 to 0.8260 (+8.76%) Severity grading: Macro-F1 increased from 0.9847 to 0.9879 (further enhancement) Validation accuracy remained stable at 84% (disease) / 97% (severity). Grad-CAM revealed both tasks focused on identical lesion regions within the same image, demonstrating exceptionally high interpretative consistency.
